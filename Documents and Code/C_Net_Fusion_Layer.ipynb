{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C-Net : Fusion Layer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xTsTVHfob5b",
        "colab_type": "text"
      },
      "source": [
        "**Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu44N2Xaou8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLXi-7czoz7o",
        "colab_type": "text"
      },
      "source": [
        "**Reading Train and Test probability values (generated by Model training code)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXmBx5E-pEVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('pred_valuest.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukfdplHApI9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = pd.read_csv('pred_values_test.csv')\n",
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2NMZF6mpPzD",
        "colab_type": "text"
      },
      "source": [
        "**Fusion Layer : Simple Exponential Smoothing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5wiibtQrQq2",
        "colab_type": "text"
      },
      "source": [
        "**Finding Optimal parameter \"alpha\" through a grid search on training data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_jgjftXpWhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_alpha_acc = 0\n",
        "max_acc = -100\n",
        "opt_alpha_loss = 0\n",
        "min_loss = 100000\n",
        "opt_alpha_f1 = 0\n",
        "f1_max = -100\n",
        "\n",
        "intervals = np.linspace(0.0, 1.0, num=21)\n",
        "y = df.values[:,-1]\n",
        "\n",
        "for alpha in tqdm(intervals):\n",
        "    count = 0\n",
        "    loss = 0\n",
        "    preds = []\n",
        "    for i in range(len(df)):\n",
        "        data = df.values[i][:-1]\n",
        "        model = SimpleExpSmoothing(data)\n",
        "        model_fit = model.fit(alpha)\n",
        "        prob = model_fit.forecast(1)[0]\n",
        "        pred = np.round(prob)\n",
        "        if pred==y[i]:\n",
        "            count = count+1\n",
        "        preds.append(pred)       \n",
        "    acc = (count/len(df))*100.0\n",
        "    loss = log_loss(y, preds)\n",
        "    f1 =  f1_score(y, preds)\n",
        "    if acc>max_acc:\n",
        "        max_acc = acc\n",
        "        opt_alpha_acc = alpha\n",
        "        \n",
        "    if loss<min_loss:\n",
        "        min_loss = loss\n",
        "        opt_alpha_loss = alpha\n",
        "        \n",
        "    if f1>f1_max:\n",
        "        f1_max = f1\n",
        "        opt_alpha_f1 = alpha"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbNRG4yCrHuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(opt_alpha_acc)\n",
        "print(max_acc)\n",
        "print(opt_alpha_loss)\n",
        "print(min_loss)\n",
        "print(opt_alpha_f1)\n",
        "print(f1_max)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs3oa93ArcnS",
        "colab_type": "text"
      },
      "source": [
        "**Making predictions on Test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSh1pBCQrkEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "predictions = []\n",
        "for i in tqdm(range(len(df2))):\n",
        "        data = df2.values[i][1:]\n",
        "        model = SimpleExpSmoothing(data)\n",
        "        model_fit = model.fit(opt_alpha_f1)\n",
        "        prob = model_fit.forecast(1)[0]\n",
        "        pred = np.round(prob)\n",
        "        if pred==1:\n",
        "            predictions.append('SARCASM')\n",
        "        else:\n",
        "            predictions.append('NOT_SARCASM')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efV7BG7UsAuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file1 = open(\"answer.txt\",\"w\")  \n",
        "\n",
        "for i in range(len(predictions)):\n",
        "  file1.write(df2['id'][i]+','+predictions[i]+'\\n')\n",
        "\n",
        "file1.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unIk5p2-taTL",
        "colab_type": "text"
      },
      "source": [
        "**Fusion Layer : Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uRjmFiRthS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_cols = ['d1', 'd2', 'response']\n",
        "X = df.loc[:, feature_cols]\n",
        "y = df.y\n",
        "X_new = df2.loc[:, feature_cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqkkqRMpuCm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X, y)\n",
        "new_pred_class = logreg.predict(X_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnSHk6fDxWmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sar = []\n",
        "for i in range(len(new_pred_class)):\n",
        "  if(new_pred_class[i]==0.0):\n",
        "    sar.append('NOT_SARCASM')\n",
        "  else:\n",
        "    sar.append('SARCASM') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gEeGD3wxmXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file1 = open(\"answer.txt\",\"w\")  \n",
        "\n",
        "for i in range(len(sar)):\n",
        "  file1.write(df2['id'][i]+','+sar[i]+'\\n')\n",
        "\n",
        "file1.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}