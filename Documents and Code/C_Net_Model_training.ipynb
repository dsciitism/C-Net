{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C-Net : Model training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZn_-3alRC0i",
        "colab_type": "text"
      },
      "source": [
        "**Installing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTfA-JTlRQCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "!pip install jsonlines"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNSfXXl0RmLT",
        "colab_type": "text"
      },
      "source": [
        "**Importing Necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyWCs-nyRp-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jsonlines  \n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
        "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
        "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "from pathlib import Path \n",
        "import os\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import random \n",
        "\n",
        "# fastai\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *\n",
        "from transformers import AdamW\n",
        "from functools import partial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oALtZH-1Ry9t",
        "colab_type": "text"
      },
      "source": [
        "**Reading Data from .csv files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKZdyFjAR9AC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training\n",
        "data_twitter = []\n",
        "path = '/content/drive/My Drive/Sarcasm shared task/sarcasm/twitter/sarcasm_detection_shared_task_twitter_training.jsonl'\n",
        "with jsonlines.open(path) as reader:\n",
        "    for obj in reader:\n",
        "        line = []\n",
        "        line.append(obj['label'])\n",
        "        line.append(obj['response'])\n",
        "        line.append(obj['context'])\n",
        "        data_twitter.append(line)\n",
        "\n",
        "data_twitter = pd.DataFrame(data_twitter, columns=['label', 'response', 'context'])\n",
        "data_twitter.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcEYAs4_2HbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing\n",
        "data_twitter_test = []\n",
        "path = '/content/drive/My Drive/Sarcasm shared task/sarcasm/twitter/sarcasm_detection_shared_task_twitter_testing.jsonl'\n",
        "with jsonlines.open(path) as reader:\n",
        "    for obj in reader:\n",
        "        line = []\n",
        "        line.append(obj['id'])\n",
        "        line.append(obj['response'])\n",
        "        line.append(obj['context'])\n",
        "        data_twitter_test.append(line)\n",
        "\n",
        "data_twitter_test = pd.DataFrame(data_twitter_test, columns=['id','response', 'context'])\n",
        "data_twitter_test.head() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5ALBId8SiyG",
        "colab_type": "text"
      },
      "source": [
        "**Storing last sentence and second-last sentence of context sets separately in different columns**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COLIpHaCSf_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d1 = []\n",
        "d2 = []\n",
        "for i in range(len(data_twitter)):\n",
        "  d1.append(data_twitter['context'][i][-2])\n",
        "  d2.append(data_twitter['context'][i][-1])\n",
        "\n",
        "data_twitter['d1'] = d1\n",
        "data_twitter['d2'] = d2\n",
        "\n",
        "data_twitter.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcwpDYC-6Ae8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d1 = []\n",
        "d2 = []\n",
        "for i in range(len(data_twitter_test)):\n",
        "  d1.append(data_twitter_test['context'][i][-2])\n",
        "  d2.append(data_twitter_test['context'][i][-1])\n",
        "\n",
        "data_twitter_test['d1'] = d1\n",
        "data_twitter_test['d2'] = d2\n",
        "\n",
        "data_twitter_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLg15nwqTijA",
        "colab_type": "text"
      },
      "source": [
        "**Choosing model architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzX-TblHTm_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_CLASSES = {\n",
        "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
        "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
        "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
        "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
        "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)}\n",
        "    \n",
        "model_type = 'bert'\n",
        "\n",
        "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc1A9ynYTzta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_class.pretrained_model_archive_map.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNJI4q27T2ak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_model_name='bert-base-uncased'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi73nsL-UTrs",
        "colab_type": "text"
      },
      "source": [
        "**Fixing seeds for reproducibility**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvCBBXZfUZzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 42\n",
        "use_fp16 = True #For half-precision calculation\n",
        "bs = 16\n",
        "\n",
        "def seed_all(seed_value):\n",
        "    random.seed(seed_value) # Python\n",
        "    np.random.seed(seed_value) # cpu vars\n",
        "    torch.manual_seed(seed_value) # cpu  vars\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
        "        torch.backends.cudnn.deterministic = True  #needed\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_all(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XCqcSYRVuWm",
        "colab_type": "text"
      },
      "source": [
        "**Defining Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhZ8Vl0yVyW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
        "\n",
        "class TransformersBaseTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
        "        self._pretrained_tokenizer = pretrained_tokenizer\n",
        "        self.max_seq_len = pretrained_tokenizer.max_len\n",
        "        self.model_type = model_type\n",
        "\n",
        "    def __call__(self, *args, **kwargs): \n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
        "        CLS = self._pretrained_tokenizer.cls_token\n",
        "        SEP = self._pretrained_tokenizer.sep_token\n",
        "        if self.model_type in ['roberta']:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
        "            tokens = [CLS] + tokens + [SEP]\n",
        "        else:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
        "            if self.model_type in ['xlnet']:\n",
        "                tokens = tokens + [SEP] +  [CLS]\n",
        "            else:\n",
        "                tokens = [CLS] + tokens + [SEP]\n",
        "        return tokens       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE4uIQIeWHVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
        "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
        "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyF8_BrnWN54",
        "colab_type": "text"
      },
      "source": [
        "**Defining Vocabulary making function. Required for Fastai.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0LvxdflWVJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformersVocab(Vocab):\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
        "        super(TransformersVocab, self).__init__(itos = [])\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
        "        \"Convert a list of tokens `t` to their ids.\"\n",
        "        return self.tokenizer.convert_tokens_to_ids(t)\n",
        "        #return self.tokenizer.encode(t)\n",
        "\n",
        "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
        "        \"Convert a list of `nums` to their tokens.\"\n",
        "        nums = np.array(nums).tolist()\n",
        "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
        "    \n",
        "    def __getstate__(self):\n",
        "        return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
        "\n",
        "    def __setstate__(self, state:dict):\n",
        "        self.itos = state['itos']\n",
        "        self.tokenizer = state['tokenizer']\n",
        "        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lMUQnFpWnVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
        "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
        "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
        "transformer_processor = [tokenize_processor, numericalize_processor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18NQHVM2Wu7u",
        "colab_type": "text"
      },
      "source": [
        "**Defining how to pad the text (depends on architecture to be used)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Hys-JVWW9Gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad_first = bool(model_type in ['xlnet'])\n",
        "pad_idx = transformer_tokenizer.pad_token_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osKOqtDcXCTx",
        "colab_type": "text"
      },
      "source": [
        "**Creating databunch for the response sentences**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaazNYMKXJPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "databunch = (TextList.from_df(data_twitter, cols='response', processor=transformer_processor)\n",
        "             .split_by_rand_pct(0.1,seed=seed)\n",
        "             .label_from_df(cols= 'label')\n",
        "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqxSb1QxXTBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
        "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
        "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
        "databunch.show_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jmN3CZFXceM",
        "colab_type": "text"
      },
      "source": [
        "**Defining the model architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z5v3-qeXmHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomTransformerModel(nn.Module):\n",
        "    def __init__(self, transformer_model: PreTrainedModel):\n",
        "        super(CustomTransformerModel,self).__init__()\n",
        "        self.transformer = transformer_model\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        \n",
        "        # attention_mask\n",
        "        # Mask to avoid performing attention on padding token indices.\n",
        "        # Mask values selected in ``[0, 1]``:\n",
        "        # ``1`` for tokens that are NOT MASKED, ``0`` for MASKED tokens.\n",
        "        attention_mask = (input_ids!=pad_idx).type(input_ids.type()) \n",
        "        \n",
        "        logits = self.transformer(input_ids,\n",
        "                                  attention_mask = attention_mask)[0]   \n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmBKD-SRXzLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = config_class.from_pretrained(pretrained_model_name)\n",
        "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
        "\n",
        "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZoWp_F8YfbI",
        "colab_type": "text"
      },
      "source": [
        "**Defining Learner**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1zi5jTSYkTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CustomAdamW = partial(AdamW, correct_bias=False)\n",
        "\n",
        "learner = Learner(databunch, \n",
        "                  custom_transformer_model, \n",
        "                  opt_func = CustomAdamW, \n",
        "                  metrics=[accuracy, error_rate])\n",
        "\n",
        "# Show graph of learner stats and metrics after each epoch.\n",
        "learner.callbacks.append(ShowGraph(learner))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK-wmq7cYyb2",
        "colab_type": "text"
      },
      "source": [
        "**Splitting Model into smaller groups**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvN6qM5EY3k4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_layers = [learner.model.transformer.bert.embeddings,\n",
        "              learner.model.transformer.bert.encoder.layer[0],\n",
        "              learner.model.transformer.bert.encoder.layer[1],\n",
        "              learner.model.transformer.bert.encoder.layer[2],\n",
        "              learner.model.transformer.bert.encoder.layer[3],\n",
        "              learner.model.transformer.bert.encoder.layer[4],\n",
        "              learner.model.transformer.bert.encoder.layer[5],\n",
        "              learner.model.transformer.bert.encoder.layer[6],\n",
        "              learner.model.transformer.bert.encoder.layer[7],\n",
        "              learner.model.transformer.bert.encoder.layer[8],\n",
        "              learner.model.transformer.bert.encoder.layer[9],\n",
        "              learner.model.transformer.bert.encoder.layer[10],\n",
        "              learner.model.transformer.bert.encoder.layer[11],\n",
        "              learner.model.transformer.bert.pooler]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqj1h0VlY-67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.split(list_layers)\n",
        "num_groups = len(learner.layer_groups)\n",
        "print('Learner split in',num_groups,'groups')\n",
        "print(learner.layer_groups)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aArMFntKZJzl",
        "colab_type": "text"
      },
      "source": [
        "**Training the Model by gradually unfreezing end layers (groups)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT_pCivQZXZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_all(seed)\n",
        "learner.freeze_to(-1)\n",
        "learner.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kk05gYuZgha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Finding optimal learning rate for slanted triangular learning rates policy\n",
        "learner.lr_find()\n",
        "learner.recorder.plot(skip_end=10,suggestion=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HY4NHcAZuhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.fit_one_cycle(2,max_lr=1e-04,moms=(0.8,0.7), callbacks=[SaveModelCallback(learner, monitor='accuracy')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G74VrXvyZ1Io",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.load('bestmodel')\n",
        "learner.save('twitter-response-bert')\n",
        "seed_all(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3_q5jUaZ7yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.freeze_to(-2)\n",
        "learner.lr_find()\n",
        "learner.recorder.plot(skip_end=10,suggestion=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bePE8j4yaGi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-5\n",
        "learner.fit_one_cycle(2, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9), callbacks=[SaveModelCallback(learner, monitor='accuracy')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgvVlBZUbGsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load('bestmodel');\n",
        "learner.freeze_to(-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdfzHzZYbTJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.fit_one_cycle(2, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9), callbacks=[SaveModelCallback(learner, monitor='accuracy')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr5qrxiObZW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.load('bestmodel');\n",
        "learner.save('twitter-response-bert')\n",
        "seed_all(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OreftTIEbceM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-5\n",
        "learner.unfreeze()\n",
        "learner.fit_one_cycle(4, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9), callbacks=[SaveModelCallback(learner, monitor='valid_loss')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUUeNUm2dNxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.load('bestmodel')\n",
        "learner.save('twitter best yet response')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSPHi4H_24Kd",
        "colab_type": "text"
      },
      "source": [
        "**Saving probability values for train and test responses**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb28IdGB1_he",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_response = []\n",
        "learner.load('twitter best yet response')\n",
        "for i in tqdm(range(len(data_twitter))):\n",
        "  pred_response.append(float(learner.predict(data_twitter['response'][i])[2][1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbFLLSMZ2hvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_response_test = []\n",
        "for i in tqdm(range(len(data_twitter_test))):\n",
        "  pred_response_test.append(float(learner.predict(data_twitter_test['response'][i])[2][1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipI2zUqx3E7S",
        "colab_type": "text"
      },
      "source": [
        "**Creating databunch for last sentence of context sets** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mm0sotQ30Gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "databunch = (TextList.from_df(data_twitter, cols='d2', processor=transformer_processor)\n",
        "             .split_by_rand_pct(0.1,seed=seed)\n",
        "             .label_from_df(cols= 'label')\n",
        "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdC0buGE37j-",
        "colab_type": "text"
      },
      "source": [
        "**Perform the same model training procedure as done while training on response sentences. Then record the probability values of train and test data last context sentences.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2sxjold4IST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_d2 = []\n",
        "learner.load('twitter best yet d2')\n",
        "for i in tqdm(range(len(data_twitter))):\n",
        "  pred_d2.append(float(learner.predict(data_twitter['d2'][i])[2][1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBcfDkGC4rJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_d2_test = []\n",
        "for i in range(len(data_twitter_test)):\n",
        "  pred_d2_test.append(float(learner.predict(data_twitter_test['d2'][i])[2][1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjTl-Amx4tZU",
        "colab_type": "text"
      },
      "source": [
        "**Creating databunch for second last sentence of context sets** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-F9fJX34x-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "databunch = (TextList.from_df(data_twitter, cols='d1', processor=transformer_processor)\n",
        "             .split_by_rand_pct(0.1,seed=seed)\n",
        "             .label_from_df(cols= 'label')\n",
        "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm_yyncG445c",
        "colab_type": "text"
      },
      "source": [
        "**Perform the same model training procedure as done while training on response sentences. Then record the probability values of train and test data second last context sentences.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pswHnV5j5AlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_d1 = []\n",
        "learner.load('twitter best yet d1')\n",
        "for i in tqdm(range(len(data_twitter))):\n",
        "  pred_d1.append(float(learner.predict(data_twitter['d1'][i])[2][1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAT_81JX5Jna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_d1_test = []\n",
        "for i in range(len(data_twitter_test)):\n",
        "  pred_d1_test.append(float(learner.predict(data_twitter_test['d1'][i])[2][1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmFr0sO55UIG",
        "colab_type": "text"
      },
      "source": [
        "**Saving all train probability values together with their labels in a csv file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSlzRfBd5eGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame([], columns=['d1', 'd2', 'response'])\n",
        "df['d1'] = pred_d1\n",
        "df['d2'] = pred_d2\n",
        "df['response'] = pred_response\n",
        "\n",
        "y = []\n",
        "for i in range(len(data_twitter)):\n",
        "  if(data_twitter['label'][i] == 'NOT_SARCASM'):\n",
        "    y.append(0)\n",
        "  else:\n",
        "    y.append(1)\n",
        "\n",
        "df['y'] = y\n",
        " \n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnD8oxtt5s0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('pred_values.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnpBBCLA6gqk",
        "colab_type": "text"
      },
      "source": [
        "**Saving all test probability values together with their labels in a csv file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qqYg4EB6ic9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame([], columns=['id', 'd1', 'd2', 'response'])\n",
        "df['id'] = data_twitter_test['id']\n",
        "df['d1'] = pred_d1_test\n",
        "df['d2'] = pred_d2_test\n",
        "df['response'] = pred_response_test\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o0FFtCr6q9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('pred_values_test.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}